# Contributing to TTE

- [Issues \& Pull Requests](#issues--pull-requests)
- [Use of AI and Automated Tools](#use-of-ai-and-automated-tools)
  - [Using AI in a Limited Capacity](#using-ai-in-a-limited-capacity)
  - ["Healing" AI-Generated Code](#healing-ai-generated-code)
- [Development Guidelines](#development-guidelines)
  - [Short Overview](#short-overview)

Thank you for your interest in pushing TTE further!

When considering contributing, please conform to the guidelines in this document.

> [!IMPORTANT]
> Also refer to the [code of conduct](./CODE_OF_CONDUCT.md).

## Issues & Pull Requests

Please use *only* the GitHub issues platform on [crowbait/typespec-typescript-emitter](https://github.com/crowbait/typespec-typescript-emitter/issues) to report bugs, problems, and feature requests.

Guidelines:

- *For issues*: you **must** include your `tspconfig` file *and* a reproducible example of TSP input resulting in your issue coming up.
- *For issues*: always search existing (open *and* closed) issues before posting yours.
- Do NOT post screenshots of any logs or output. Always use text.
- Format your issue / PR appropriately; code and log output go in [code blocks](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code).
- Keep your issue / PR *concise*, while also including all *relevant* information. Sufficiently explain your issue / PR, but do not turn it into an essay.
- *For PRs*: include example TSP input in your pull request. This makes it *much* easier to quickly verify and understand your approach and solution.
- Use the issue / PR template.

If your issue or PR does not follow these guidelines, you may be asked to rewrite it or it might just be closed entirely.

## Use of AI and Automated Tools

> [!IMPORTANT]
> Do **NOT** submit any issue or pull request entirely generated by AI (LLMs) or other automated tools.

You **CAN** use AI tools for:

- proofreading
- conceptual help (e.g. writing code while being *guided* by an AI, *without* just copying the code it generates; also see below: [Using AI in a Limited Capacity](#using-ai-in-a-limited-capacity))
- creating JSDoc comments, **as long as they are not needlessly verbose** (concise documentation is welcome; multi-page explanations are not)

You **CAN NOT** use AI tools for:

- generating your issue / PR text
- generating the majority of your code

> [!WARNING]
> Any PR or issue tagged as being co-authored by AI tools **can not** be accepted.
> This is due to both due-diligence concerns regarding the code base and the still not entirely clear moral and legal implications of LLM-generated code ownership.

This helps identify potential issues or improvements and ensures you fully understand the problem or solution: for issues, you must be able to answer follow-up questions; for PRs, you must have a complete understanding of *every single line of code* you submit.
This ultimately boils down to the responsibilities of FOSS contributors.

**Note**: these restrictions are neither meant to bash on LLM users (I use them myself for various things), oppose AI in general, or annoy you specifically because you would like to use an AI for your contribution. They are meant to ensure efficiency (because AI issues and PRs tend to be around 3 times longer than if a human had written them, without providing any additional relevant information) and help protect the long-term health of the code base.

### Using AI in a Limited Capacity

You can use AI tools to *assist* you in coding, provided you don't have it do most of the work.

Acceptable:

- asking how something could be implemented in TypeScript, using the response as a starting point for your *own* solution
- giving it a broken piece of code you can't find the bug in and using its *explanation* of the issue to fix the bug - again, making sure you *understand* the issue and the fix

Unacceptable:

- describing a goal and copy-pasting the generated code
- submitting code you do not fully understand

You must understand every line you contribute and evaluate *why* it exists and whether better alternatives are available.

Rules of thumb:

- If you have to ask the AI to fix a bug it produced earlier, you have not been exercising due diligence.
- If the AI performs changes *directly* on your code base, you no longer *in* the development loop, you are adjacent to it, merely influencing it.

### "Healing" AI-Generated Code

You can force yourself back *into* the loop by manually reworking AI-generated code.

1. clone a fresh copy of the repository
2. open your previous changes side-by-side
3. re-type the code manually, piece by piece

This process encourages deliberate review and helps you evaluate what the LLM produced, why it works, and whether better solutions exist.

## Development Guidelines

Thank you very much for considering investing time into this project!

For the smoothest contributing experience, please adhere these guidelines:

- Please use [conventional commits](https://www.conventionalcommits.org/en/v1.0.0/#summary).
- If your contribution expands functionality, please consider drafting tests for it. As the testing framework is in dire need of being rewritten, this is not "enforced", but contributing tests alongside your code would certainly be nice.

### Short Overview

This section roughly outlines the inner workings of the library.

- `lib.ts` defines primarily emitter options
- `emitter.ts` is the main entry point

`$onEmit` calls the actual emitters defined in `emit_*` files.
These each traverse the program, recursively collecting the objects they are interested in (emittable types, operations, ...) from the root namespaces specified by the user.

The primary resolution of types and typeguards starts in `resolve/Resolvable.ts`.
It defines an abstract class which both contains static functions to resolve types as well as inherited methods each type resolver implements and uses to recursively resolve.
Each resolvable type defines its methods in an inherited class, in `resolve/types/[type].ts`.

The primary flow of type resolution is quite simple:

- `static Resolvable.resolve` calls `static Resolvable.for`, which returns a `Resolvable` instance for the specific type (we will call this instance `rt`, for "resolvable type")
- `rt.resolve` first checks a list of all types found in the program - even if they have not been yet resolved, they will be and then will be emitted - so they should just be referenced. This returns the name and skips all further resolution, ending the process here.
- `rt.type` or `rt.typeguard` are invoked: these are defined for each type in its class. Depending on the type, these either resolve directly, ending the process here, or have other types "within" them (unions or models, for example, have this). In this case, `rt.resolveNested` is called, which finishes the recursive loop by calling `static Resolvable.resolve` on the "child" type.

Most of these methods do not return data, because they mutate an "output" object passed as a parameter. This has proven to be much more concise than passing return values up and down the chain.
Also to be considered is the `hasVisibility` flag showing up at many points. This is used to ultimately determine whether a type needs lifecycle visibility handling in any way (because if any part of it does, so does the whole thing).
